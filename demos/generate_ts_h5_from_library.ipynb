{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate TimeSeries H5 from Library Profile to import in Web GUI\n",
    "\n",
    "\n",
    "TVB has the custom notion of \"profile\". Based on the selected TVB profile, we enable/disable some TVB modules and default features (storage, load defaults).\n",
    "\n",
    "We make a clear distinction between running TVB under WEB_PROFILE or LIBRARY_PROFILE.\n",
    "\n",
    "Currently it is not possible to switch in the same code from one TVB profile to another, but it is  possible to share data, as described in the current demo. \n",
    "\n",
    "You can find more info about TVB profiles here: http://docs.thevirtualbrain.org/manuals/UserGuide/UserGuide-Shell.html#tvb-profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "\n",
    "Let us start by running a standard TVB simulation, with the LIBRARY_PROFILE \n",
    "(from tvb.simulator.lab import * will set the LIBRARY_PROFILE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['f', 'datetime']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "%pylab nbagg\n",
    "from tvb.simulator.lab import *\n",
    "from tvb.datatypes import time_series\n",
    "from tvb.basic.config import settings\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  File 'hemispheres' not found in ZIP.\n"
     ]
    }
   ],
   "source": [
    "jrm = models.JansenRit(mu=numpy.array([0.]), v0=numpy.array([6.]))\n",
    "monitor = monitors.TemporalAverage(period=2 ** -2)\n",
    "\n",
    "phi_n_scaling = (jrm.a * jrm.A * (jrm.p_max-jrm.p_min) * 0.5 )**2 / 2.\n",
    "sigma         = numpy.zeros(6) \n",
    "sigma[3]      = phi_n_scaling\n",
    "\n",
    "# the other aspects of the simulator are standard\n",
    "sim = simulator.Simulator(\n",
    "    model=jrm,\n",
    "    connectivity=connectivity.Connectivity.from_file(),\n",
    "    coupling=coupling.SigmoidalJansenRit(a=numpy.array([10.0])),\n",
    "    integrator=integrators.HeunStochastic(dt=2 ** -4, noise=noise.Additive(nsig=numpy.array([sigma]))),\n",
    "    monitors=(monitor,),\n",
    "    simulation_length=1e3,\n",
    ").configure()\n",
    "\n",
    "# run it\n",
    "(time_array, data_array), = sim.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "\n",
    "#### 2.1 Define some helper functions for writing an H5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "BOOL_VALUE_PREFIX = \"bool:\"\n",
    "DATETIME_VALUE_PREFIX = \"datetime:\"\n",
    "DATE_TIME_FORMAT = '%Y-%m-%d %H:%M:%S.%f'\n",
    "\n",
    "def date2string(date_input, complex_format=True, date_format=None):\n",
    "    \"\"\"Convert date into string, after internal format\"\"\"\n",
    "    if date_input is None:\n",
    "        return \"None\"\n",
    "\n",
    "    if date_format is not None:\n",
    "        return date_input.strftime(date_format)\n",
    "\n",
    "    if complex_format:\n",
    "        return date_input.strftime(COMPLEX_TIME_FORMAT)\n",
    "    return date_input.strftime(SIMPLE_TIME_FORMAT)\n",
    "\n",
    "\n",
    "def serialize_value(value):\n",
    "    \"\"\"\n",
    "    This method takes a value which will be stored as metadata and \n",
    "    apply some transformation if necessary\n",
    "      \n",
    "    :param value: value which is planned to be stored\n",
    "    :returns:  value to be stored\n",
    "     \"\"\"\n",
    "    if value is None:\n",
    "        return ''\n",
    "    # Force unicode strings to simple strings.\n",
    "    if isinstance(value, unicode):\n",
    "        return str(value)\n",
    "    # Transform boolean to string and prefix it\n",
    "    elif isinstance(value, bool):\n",
    "        return BOOL_VALUE_PREFIX + str(value)\n",
    "    # Transform date to string and append prefix\n",
    "    elif isinstance(value, datetime):\n",
    "        return DATETIME_VALUE_PREFIX + date2string(value, date_format=DATE_TIME_FORMAT)\n",
    "    else:\n",
    "        return json.dumps(value)\n",
    "    \n",
    "    \n",
    "def generate_guid():\n",
    "    \"\"\" \n",
    "    Generate new Global Unique Identifier.\n",
    "    This identifier should be unique per each station, \n",
    "    and unique for different machines.\n",
    "    \"\"\"\n",
    "    return str(uuid.uuid1())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2  Now actually write the simulation result in a H5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "f = h5py.File(\"TimeSeriesRegion.h5\", 'w')\n",
    "\n",
    "series_of_time = time_series.TimeSeries(data=data_array, time=time_array, sample_period=monitor.period)\n",
    "state_variable_dimension_name = series_of_time.labels_ordering[1]\n",
    "selected_vois = [jrm.variables_of_interest[idx] for idx in monitor.voi]\n",
    "series_of_time.labels_dimensions[state_variable_dimension_name] = selected_vois\n",
    "series_of_time.configure()\n",
    "\n",
    "time_set = f.create_dataset(\"time\",data=series_of_time.time, maxshape=(None,))\n",
    "time_set.attrs['TVB_Minimum'] = np.min(series_of_time.time)\n",
    "time_set.attrs['TVB_Maximum'] = np.max(series_of_time.time)\n",
    "time_set.attrs['TVB_Mean'] = np.mean(series_of_time.time)\n",
    "\n",
    "data_set = f.create_dataset(\"data\",data=series_of_time.data)\n",
    "data_set.attrs['TVB_Minimum'] = np.min(series_of_time.data)\n",
    "data_set.attrs['TVB_Maximum'] = np.max(series_of_time.data)\n",
    "data_set.attrs['TVB_Mean'] = np.mean(series_of_time.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 And make sure all necessary metadata is in place in the H5 file, for TVB web GUI to recognize it at import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvb.basic.profile import TvbProfile\n",
    "\n",
    "f.attrs['TVB_Connectivity'] = \"f6be362b-5bb4-11e5-8b0d-a45e60e5b22f\"\n",
    "f.attrs['TVB_Create_date'] = serialize_value(datetime.now())\n",
    "f.attrs['TVB_Data_version'] = TvbProfile.current.version.DATA_VERSION\n",
    "f.attrs['TVB_Gid'] = generate_guid()\n",
    "f.attrs['TVB_Has_surface_mapping'] = \"true\"\n",
    "f.attrs['TVB_Has_volume_mapping'] = \"false\"\n",
    "f.attrs['TVB_Invalid'] = serialize_value(False)\n",
    "f.attrs['TVB_Is_nan'] = serialize_value(bool(np.isnan(data_array).any()))\n",
    "f.attrs['TVB_Labels_dimensions'] = serialize_value(series_of_time.labels_dimensions)\n",
    "f.attrs['TVB_Labels_ordering'] = serialize_value(series_of_time.labels_ordering)\n",
    "f.attrs['TVB_Length_1d'] = serialize_value(series_of_time.length_1d)\n",
    "f.attrs['TVB_Length_2d'] = serialize_value(series_of_time.length_2d)\n",
    "f.attrs['TVB_Length_3d'] = serialize_value(series_of_time.length_3d)\n",
    "f.attrs['TVB_Length_4d'] = serialize_value(series_of_time.length_4d)\n",
    "f.attrs['TVB_Module'] = \"tvb.datatypes.time_series\"\n",
    "f.attrs['TVB_Nr_dimensions'] = serialize_value(series_of_time.nr_dimensions)\n",
    "f.attrs['TVB_Region_mapping'] = \"002d1d23-5bb5-11e5-999a-a45e60e5b22f\"\n",
    "f.attrs['TVB_Sample_period'] = serialize_value(series_of_time.sample_period)\n",
    "f.attrs['TVB_Sample_period_unit'] = serialize_value(series_of_time.sample_period_unit)\n",
    "f.attrs['TVB_Sample_rate'] = serialize_value(series_of_time.sample_rate)\n",
    "f.attrs['TVB_Start_time'] = serialize_value(series_of_time.start_time)\n",
    "f.attrs['TVB_State'] = \"INTERMEDIATE\"\n",
    "f.attrs['TVB_Subject'] = \"FromIPython\"\n",
    "f.attrs['TVB_Title'] = serialize_value(series_of_time.title)\n",
    "f.attrs['TVB_Type'] = \"TimeSeriesRegion\"\n",
    "f.attrs['TVB_User_tag_1'] = \"You can type any text you want here\"\n",
    "f.attrs['TVB_User_tag_2'] = \"\"\n",
    "f.attrs['TVB_User_tag_3'] = \"\"\n",
    "f.attrs['TVB_User_tag_4'] = \"\"\n",
    "f.attrs['TVB_User_tag_5'] = \"\"\n",
    "f.attrs['TVB_Visible'] = serialize_value(True)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 2.4  Now you should have a file named \"TimeSeriesRegion.h5\" in the current folder where ipython notebook has been launched. \n",
    "\n",
    "You can take this \"TimeSeriesRegion.h5\" file and import it into TVB web GUI, as described here:\n",
    "http://docs.thevirtualbrain.org/manuals/UserGuide/UserGuide-UI_Project.html#data-structure\n",
    "\n",
    "After import in TVB web GUI, you will have a new TimeSeriesRegion file in your current project, which can be used with TVB web visualizers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
