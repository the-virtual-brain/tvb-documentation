{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Modeling The Impact of Structural Lesions -- Part III: Offline Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will analyze simulated BOLD signals obtained using TVB 1.1-Linux-64 web interface. \n",
    "\n",
    "If you want to see the strategies used to model lesions, check the **Tutorial: Modeling The Impact of Structural Lesions  -- Part I: Modeling Lesions**.   \n",
    "\n",
    "The parameters used for the neural mass model can be found in the **Tutorial: Modeling The Impact of Structural Lesions  -- Part II: The Brain Network model**.   \n",
    "The simulated time-series are in the project folder, you can either import this file thorugh the interface or use the individual .h5 files: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Background\n",
    "----------\n",
    "\n",
    "*Functional connectivity* (FC) in this case refers to the matrix of Pearson correlation coefficients between pair of simulated BOLD time-series. \n",
    "\n",
    "If you do not have the BOLD signals, but only the time-series corresponding to the 'neural activity', that's ok. \n",
    "In TVB you can find several alternatives of the Balloon-Windkessel [1] to compute those offline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balloon model - BOLD signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvb.analyzers.fmri_balloon as bold\n",
    "import tvb.datatypes.time_series as time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function expects a TimeSeries datatype, so it is neccesary to create one instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default this model doesn't perform any operation on the input data. There are some theories that suggest that the neural input is the sum of both the excitatory and inhibitory activity -- if both populations are actually represented in the model. Additionally, \n",
    "In the case of the balloon model the neural activity is assumed to represent a rate. For that reason, when a model like the one we are using now, described a quantity like the membrane potential, it is possible to apply a transformation to obtain a rate (derivative).\n",
    "\n",
    "\n",
    "A demo script making use of the Balloon model is available at ~/scientific_library/tvb/simulator/demos/bold_fmri_balloon_region.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulated (convolution based) BOLD signals \n",
    "\n",
    "We'll have a look at the simulated BOLD signals produced by one of tvb monitors: the BOLD monitor. The output is a convolution between a kernel function (HRF) and the neural activity time-series. You can have a look at the **Tutorial: Exploring The BOLD Monitor** where the different HRF kernels are displayed. \n",
    "\n",
    "We selected a Gamma kernel. See [1] for more details. The following time-series are the BOLD signals of the control Brain Network Model (no lesion).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "matplotlib.rcParams.update({'font.size': 22})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll aggregate the 998 regions to 66 regions. To do that we need a mapping. You can find the index vector under \n",
    "\n",
    "    ~/simulator/files/connectivity/hagmann_hemisphere_both_subcortical_false_998/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Change to the appropriate path here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "/Users/paupau/TVB-trunk/trunk/scientific_library/tvb/simulator/files/connectivity/hagmann_hemisphere_both_subcortical_false_998/region_mapping_raw_998_raw_66.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-03559b2aece1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmapping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/Users/paupau/TVB-trunk/trunk/scientific_library/tvb/simulator/files/connectivity/hagmann_hemisphere_both_subcortical_false_998/region_mapping_raw_998_raw_66.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tvb-run3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[0;32m    960\u001b[0m             \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 962\u001b[1;33m             \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    963\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'encoding'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'latin1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m             \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tvb-run3\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tvb-run3\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[0;32m    622\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[0;32m    623\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 624\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s not found.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    625\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: /Users/paupau/TVB-trunk/trunk/scientific_library/tvb/simulator/files/connectivity/hagmann_hemisphere_both_subcortical_false_998/region_mapping_raw_998_raw_66.txt not found."
     ]
    }
   ],
   "source": [
    "mapping = numpy.loadtxt('/Users/paupau/TVB-trunk/trunk/scientific_library/tvb/simulator/files/connectivity/hagmann_hemisphere_both_subcortical_false_998/region_mapping_raw_998_raw_66.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to aggregate according to this mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_average_time_series(mapping, time_series):\n",
    "    \"\"\"\n",
    "    Aggregate the 998 (nodes) regions into 66 (new_number_f_nodes) ROIs\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    mapping array\n",
    "            index vector defining the sets of regions in the 998 connectome that will be averaged into one region.\n",
    "    time_series nd array\n",
    "            simulated time series of shape time_points x nodes\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    average_time_series nd array\n",
    "            'spatially' averaged time series of shape time_points x new_number_of_nodes\n",
    "            \n",
    "    \n",
    "    \"\"\"\n",
    "    regions = numpy.unique(mapping)\n",
    "    average_time_series = numpy.zeros((time_series.shape[0], (len(regions))))\n",
    "        \n",
    "    for k in regions:\n",
    "        ts = time_series[:, mapping == k]\n",
    "        avg_ts = numpy.mean(ts, axis=1)\n",
    "        average_time_series[:, k] = avg_ts\n",
    "    \n",
    "    return average_time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functional Connectivity: Correlation coefficients matrices:\n",
    "\n",
    "Unpack the '2013-11-26_17-14_DataTypeGroup_TimeSeries.zip' inside the data/ folder\n",
    "Unpack the '2013-11-26_18-03_DataTypeGroup_TimeSeries.zip' inside the data/ folder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results with time-delays\n",
    "\n",
    "**NOTE:** Change the root path accordingly - give an absolute path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root  = '/Users/paupau/trunk/tvb-handbook/tvbmodl/code/data/2013-11-26_17-14_DataTypeGroup_TimeSeries/' \n",
    "flist = glob.glob(root + '*/*.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 timepoint per minute - 10 minutes\n",
    "FC = numpy.zeros((66, 66, len(flist)))\n",
    "for f_ix, files in enumerate(flist):\n",
    "    f   = h5py.File(files)\n",
    "    FC[:, :, f_ix]  = numpy.corrcoef((compute_average_time_series(mapping, f['data'][60:, 0, :, 0])).T)\n",
    "    f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delays\n",
    "%pylab --no-import-all inline\n",
    "matplotlib.rcParams.update({'font.size': 22})\n",
    "fig = plt.figure(2, (20., 20.))\n",
    "lesion_centres = [57, 86, 138, 162, 194, 247, 308, 323, 360, 439, 472, 555, 584, 636, 662, 692, 746, 810, 821, 856, 938, 971, 'Original']\n",
    "\n",
    "cmap = brewer2mpl.get_map('RdBu', 'diverging', 11, reverse=True).mpl_colormap\n",
    "\n",
    "for i in range(len(flist)-1):\n",
    "    \n",
    "    ax1 = plt.subplot(5, 5, i+1)\n",
    "    plt.pcolormesh(numpy.flipud(FC[:, :, i]), cmap=cmap, vmax=0.4, vmin=-0.4)\n",
    "    euclidean_distance = numpy.sqrt((FC[:, :, -1] - FC[:, :, i])**2).sum()\n",
    "    plt.ylim([0, 66])\n",
    "    plt.xlim([0, 66])\n",
    "    ax1.set_xticklabels( () )\n",
    "    ax1.set_yticklabels( () )\n",
    "    ax1.set_title('L' + str(lesion_centres[i]) + '. dFC: %d' % euclidean_distance)\n",
    "    if i ==21:\n",
    "        if i ==21:\n",
    "    # [left, bottom, width, height] where all quantities are in fractions of figure width and height. \n",
    "            fig.subplots_adjust(right=0.9)\n",
    "            cbar_ax = fig.add_axes([0.95, 0.12, 0.05, 0.8])\n",
    "            plt.colorbar(cmap=cmap, cax=cbar_ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results without time-delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root  = '/Users/paupau/trunk/tvb-handbook/tvbmodl/code/data/2013-11-26_18-03_DataTypeGroup_TimeSeries/' \n",
    "flist = glob.glob(root + '*/*.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 timepoint per minute - 10 minutes\n",
    "FC_nodelays = numpy.zeros((66, 66, len(flist)))\n",
    "for f_ix, files in enumerate(flist):\n",
    "    f   = h5py.File(files)\n",
    "    FC_nodelays[:, :, f_ix]  = numpy.corrcoef((compute_average_time_series(mapping, f['data'][60:, 0, :, 0])).T)\n",
    "    f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No - Delays\n",
    "fig = []\n",
    "%pylab --no-import-all inline\n",
    "matplotlib.rcParams.update({'font.size': 22})\n",
    "fig = plt.figure(3, (20., 20.))\n",
    "lesion_centres = [57, 86, 138, 162, 194, 247, 308, 323, 360, 439, 472, 555, 584, 636, 662, 692, 746, 810, 821, 856, 938, 971, 'Original']\n",
    "\n",
    "for i in range(len(flist)-1):\n",
    "    ax1 = plt.subplot(5, 5, i+4)\n",
    "    plt.pcolormesh(numpy.flipud(FC_nodelays[:, :, i]), cmap=cmap, vmax=0.4, vmin=-0.4)\n",
    "    euclidean_distance = numpy.sqrt((FC_nodelays[:, :, -1] - FC_nodelays[:, :, i])**2).sum()\n",
    "    plt.ylim([0, 66])\n",
    "    plt.xlim([0, 66])\n",
    "    ax1.set_xticklabels( () )\n",
    "    ax1.set_yticklabels( () )\n",
    "    ax1.set_title('L' + str(lesion_centres[i]) + '. dFC: %03d' % euclidean_distance)\n",
    "    if i ==21:\n",
    "    # [left, bottom, width, height] where all quantities are in fractions of figure width and height. \n",
    "      fig.subplots_adjust(left=0.1)\n",
    "      cbar_ax = fig.add_axes([0., 0.12, 0.05, 0.8])\n",
    "      plt.colorbar(cmap=cmap, cax=cbar_ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(data, colours=None):\n",
    "    if colours is None:\n",
    "        colours = [\"#348ABD\", \"#FF4C4C\"]\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=(20,10))\n",
    "    rh = abs(data[:11])\n",
    "    lh = abs(data)[11:]\n",
    "\n",
    "    xticks = numpy.arange(22)\n",
    "    even_ticks = xticks[0::2]\n",
    "    odd_ticks = xticks[1::2]\n",
    "    r1 = ax.bar(even_ticks+0.5,rh, alpha=0.75, width=1., color=colours[0], lw=\"3\", edgecolor=colours[0], label='RH')\n",
    "    r2 = ax.bar(odd_ticks+0.5,lh, alpha=0.75, width=1., color=colours[1], lw=\"3\", edgecolor=colours[1], label='LH')\n",
    "\n",
    "    lesion_centres_labels = ['L057', 'L555', \n",
    "                  'L086', 'L584', \n",
    "                  'L138', 'L636',\n",
    "                  'L162', 'L662', \n",
    "                  'L194', 'L692', \n",
    "                  'L247', 'L746', \n",
    "                  'L308', 'L810',\n",
    "                  'L323', 'L821', \n",
    "                  'L360', 'L856', \n",
    "                  'L439', 'L938', \n",
    "                  'L472', 'L971']\n",
    "    plt.xlim([0.0, 23])\n",
    "    plt.ylim([0.0, 3.0])\n",
    "    ax.set_xticks(xticks+1.0)\n",
    "    ax.set_xticklabels(lesion_centres_labels, fontsize=16)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_FC = []\n",
    "diff_FC_nodelays = []\n",
    "diff_FC_d_nd = []\n",
    "for i in range(len(flist)):\n",
    "    diff_FC.append(numpy.sqrt((FC[:, :, i] - FC[:, :, -1])**2).sum())\n",
    "    diff_FC_nodelays.append(numpy.sqrt((FC_nodelays[:, :, i] - FC_nodelays[:, :, -1])**2).sum())\n",
    "    diff_FC_d_nd.append(numpy.sqrt((FC[:, :, i] - FC_nodelays[:, :, i])**2).sum())\n",
    "\n",
    "    \n",
    "diff_FC = numpy.array(diff_FC[:-1])\n",
    "diff_FC_nodelays = numpy.array(diff_FC_nodelays[:-1])\n",
    "diff_FC_d_nd = numpy.array(diff_FC_d_nd[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = diff_FC_nodelays - diff_FC_nodelays.mean()\n",
    "plot_hist(data / data.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = diff_FC - diff_FC.mean()\n",
    "plot_hist(data/ data.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = diff_FC_d_nd - diff_FC_d_nd.mean()\n",
    "colours = [\"#66C2A5\", \"#FC8D62\", \"#8DA0CB\", \"#E78AC3\", \"#A6D854\", \"#ffD92F\", \"#E5C494\"]\n",
    "plot_hist(data / data.std(), colours[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the some intersting examples ...\n",
    "fig = plt.figure(4, (20., 15.))\n",
    "\n",
    "\n",
    "# Delays\n",
    "ax1 = plt.subplot(221)\n",
    "plt.pcolormesh(numpy.flipud(FC[:, :, -1]), cmap=cmap, vmax=0.4, vmin=-0.4)\n",
    "plt.ylim([0, 66])\n",
    "plt.xlim([0, 66])\n",
    "ax1.set_xticklabels( () )\n",
    "ax1.set_yticklabels( () )\n",
    "ax1.set_title('FC - Control - Delays')\n",
    "plt.colorbar(cmap=cmap)\n",
    "\n",
    "# No delays\n",
    "ax2 = plt.subplot(222)\n",
    "ax2.pcolormesh(numpy.flipud(FC_nodelays[:, :, -1]), cmap=cmap, vmax=0.4, vmin=-0.4)\n",
    "plt.ylim([0, 66])\n",
    "plt.xlim([0, 66])\n",
    "ax2.set_xticklabels( () )\n",
    "ax2.set_yticklabels( () )\n",
    "ax2.set_title('FC - Control - No delays')\n",
    "plt.colorbar(cmap=cmap)\n",
    "\n",
    "# Delays\n",
    "ax3 = plt.subplot(223)\n",
    "plt.pcolormesh(numpy.flipud(FC[:, :, 4]), cmap=cmap, vmax=0.4, vmin=-0.4)\n",
    "plt.ylim([0, 66])\n",
    "plt.xlim([0, 66])\n",
    "ax3.set_xticklabels( () )\n",
    "ax3.set_yticklabels( () )\n",
    "ax3.set_title('FC - L194 - Delays')\n",
    "plt.colorbar(cmap=cmap)\n",
    "\n",
    "# No delays\n",
    "ax4 = plt.subplot(224)\n",
    "ax4.pcolormesh(numpy.flipud(FC_nodelays[:, :, 4]), cmap=cmap, vmax=0.4, vmin=-0.4)\n",
    "plt.ylim([0, 66])\n",
    "plt.xlim([0, 66])\n",
    "ax4.set_xticklabels( () )\n",
    "ax4.set_yticklabels( () )\n",
    "ax4.set_title('FC - L194 - No delays')\n",
    "plt.colorbar(cmap=cmap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Boynton et al. 2012. Linear systems analysis of the fMRI signal. Neuroimage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
